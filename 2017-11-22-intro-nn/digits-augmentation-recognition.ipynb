{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2017-11-22 deep learning club\n",
    "# digits regognition (cifar10) + data augmentation \n",
    "# concepts covered: \n",
    "# - [x] NN with dense layers\n",
    "# - [x] not so deep cNN\n",
    "# - [x] weights initialization\n",
    "# - data augmentation\n",
    "# - [x] saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import load_model\n",
    "\n",
    "# convenient imports\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys,os,time,random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg');\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('gray');\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread, imsave\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from os import walk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"keras\", keras.__version__)\n",
    "print(\"tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the backend the ordering of the channels\n",
    "print(keras.backend.backend())\n",
    "print(keras.backend.image_dim_ordering())\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reproducibility\n",
    "answer_to_all_questions = seed = 1331\n",
    "random.seed(answer_to_all_questions)\n",
    "np.random.seed(answer_to_all_questions)\n",
    "tf.set_random_seed(answer_to_all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')[:,:,:, None]\n",
    "x_test = x_test.astype('float32')[:,:,:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "num_classes = 10\n",
    "\n",
    "num_channels = 1\n",
    "\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], num_channels)\n",
    "\n",
    "print (\"input shape:\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put the show images here \n",
    "# examples of the images from the training set \n",
    "n_images_show = 7\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.title(\"Example images\")\n",
    "plt.imshow(np.concatenate(x_train[:n_images_show, :, :, 0],axis=1), interpolation='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fully connected model\n",
    "def create_dense_model(initializer):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "    model.add(Dense(100, kernel_initializer=initializer))\n",
    "    model.add(keras.layers.normalization.BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer=initializer))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initializers = ['zeros', 'ones', 'random_uniform', 'glorot_uniform']\n",
    "model = create_dense_model(initializers[0])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Available data:\", history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.figure\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put the show images here \n",
    "# examples of the images from the training set \n",
    "n_images_show = 7\n",
    "# plt.rcParams['figure.figsize'] = (15, 5)\n",
    "# plt.title(\"Example images\")\n",
    "sample = x_test[np.random.choice(x_test.shape[0], n_images_show, replace=False)]\n",
    "\n",
    "predicted = model.predict(sample).argmax(-1)\n",
    "plt.figure(figsize=(16,8))\n",
    "for i in range(n_images_show):\n",
    "    plt.subplot(1, n_images_show, i+1)\n",
    "    plt.imshow(sample[i, :, :, 0], interpolation='none',)\n",
    "    plt.text(0, 0, predicted[i], color='black', \n",
    "             bbox=dict(facecolor='white', alpha=1))\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "# for j in range (0,n_images_show):\n",
    "#     textstr = j\n",
    "#     props = dict(facecolor='white', alpha=1)\n",
    "#     # place a text box in upper left in axes coords\n",
    "#     ax.text(0.01+j*0.14, 0.95, textstr, transform=ax.transAxes, fontsize=12,\n",
    "#             verticalalignment='top', bbox=props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_simple_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (5, 5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model_simple_conv_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving model using keras \n",
    "model_path = \"data/nn-model.h5py\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading model from keras \n",
    "if 'model' in globals(): # check that the model is defined\n",
    "    del model \n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that we loaded the same model \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "# in case of images and labels we have to use the following approach: \n",
    "# create 2 instances with the same arguments: \n",
    "shift = 0.02\n",
    "angle = 45\n",
    "image_data_gen_args = dict(featurewise_center=False, \n",
    "                             featurewise_std_normalization=False, \n",
    "                             # zca_whitening=True, \n",
    "                             rotation_range=angle,\n",
    "                             width_shift_range=shift, \n",
    "                             height_shift_range=shift,\n",
    "                             fill_mode = 'wrap',\n",
    "                             # cval = 0,\n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=True)\n",
    "\n",
    "datagen = ImageDataGenerator(**image_data_gen_args)\n",
    "# labelgen = ImageDataGenerator(**image_data_gen_args)\n",
    "\n",
    "datagen.fit(x_train, augment=True, seed=seed)\n",
    "# labelgen.fit(np_dataset_l_train, augment=True, seed=seed)\n",
    "\n",
    "# image_generator = datagen.flow(\n",
    "#     x_train,\n",
    "#     seed=seed, \n",
    "#     batch_size = batch_size,\n",
    "#     save_to_dir='data/aug', save_prefix='cell', save_format='png')\n",
    "# label_generator = labelgen.flow(\n",
    "#     np_dataset_l_train,\n",
    "#     seed=seed,\n",
    "#     batch_size = batch_size,\n",
    "#     save_to_dir='data/aug', save_prefix='dots', save_format='png')\n",
    "\n",
    "j_batch = 0\n",
    "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
    "    print(j_batch, \"th batch with the shapes:\", X_batch.shape, y_batch.shape)   \n",
    "    \n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break\n",
    "    \n",
    "    j_batch += 1;\n",
    "    if (j_batch >= 10):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
