{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2017-11-22 deep learning club\n",
    "# digits regognition (mnist) + data augmentation \n",
    "# https://keras.io\n",
    "# concepts covered: \n",
    "# - [x] NN with dense layers\n",
    "# - [x] not so deep cNN\n",
    "# - [x] weights initialization\n",
    "# - [x] data augmentation\n",
    "# - [x] saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import load_model\n",
    "\n",
    "# convenient imports\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg');\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('Greys');\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"keras\", keras.__version__)\n",
    "print(\"tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the backend the ordering of the channels\n",
    "print(keras.backend.backend())\n",
    "print(keras.backend.image_dim_ordering())\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "# Check again that all GPU's are available to the\n",
    "# And set the corresponding variables,\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "num_gpu = len(get_available_gpus())\n",
    "print(\"Total GPU's count:\", num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reproducibility\n",
    "seed = 1331\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('train samples:', x_train.shape[0])\n",
    "print('test samples:', x_test.shape[0])\n",
    "# IMP: trick to make the CNN work: add extra dimension [:,:,:, None] that corresponds to the number of channels \n",
    "x_train = x_train.astype('float32')[:,:,:, None]\n",
    "x_test = x_test.astype('float32')[:,:,:, None]\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 30000 # 128\n",
    "epochs = 10\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], num_channels)\n",
    "\n",
    "print (\"input shape:\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put the show images here \n",
    "# examples of the images from the training set \n",
    "n_images_show = 7\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.imshow(np.concatenate(x_train[:n_images_show, :, :, 0],axis=1), interpolation='none')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fully connected model\n",
    "def create_dense_model(initializer):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "    model.add(Dense(100, kernel_initializer=initializer))\n",
    "    model.add(keras.layers.normalization.BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer=initializer))\n",
    "\n",
    "    # initiate SGD optimizer\n",
    "    # opt = keras.optimizers.SGD(lr=0.0001, decay=0.0, momentum=0.0, nesterov=False)\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initializers = ['zeros', 'ones', 'random_uniform', 'glorot_uniform']\n",
    "model = create_dense_model(initializers[3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plots the training process\n",
    "def plot_history(history):\n",
    "    print(\"Available data:\", history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.figure\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put the show images here \n",
    "# examples of the images from the training set \n",
    "n_images_show = 7\n",
    "sample = x_test[np.random.choice(x_test.shape[0], n_images_show, replace=False)]\n",
    "predicted = model.predict(sample).argmax(-1)\n",
    "plt.figure(figsize=(16,8))\n",
    "for i in range(n_images_show):\n",
    "    plt.subplot(1, n_images_show, i+1)\n",
    "    plt.imshow(sample[i, :, :, 0], interpolation='none')\n",
    "    plt.text(0, 0, predicted[i], color='black', \n",
    "             bbox=dict(facecolor='white', alpha=1))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conv net\n",
    "def model_simple_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (5, 5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate SGD optimizer\n",
    "    # opt = keras.optimizers.SGD(lr=0.0001, decay=0.0, momentum=0.0, nesterov=False)\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model_simple_conv_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving model using keras \n",
    "directory = \"data/models/\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "model_path = directory + \"nn-model.h5py\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading model from keras \n",
    "if 'model' in globals(): # check that the model is defined\n",
    "    del model \n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that we loaded the same model \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pretty way to show the digits\n",
    "def plot_digits(x_data, y_pred):\n",
    "    for i in range(0, n_images_show):\n",
    "        plt.subplot(1, n_images_show, i + 1)\n",
    "        plt.imshow(x_data[i].reshape(input_shape[0], input_shape[1]), interpolation='none')    \n",
    "        plt.text(0, 0, y_pred[i], color='black', bbox=dict(facecolor='white', alpha=1))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that the model is actually working \n",
    "proba = model.predict(x_test)\n",
    "digits_predicted = np.argmax(proba, axis=1)\n",
    "\n",
    "plot_digits(x_test, digits_predicted);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "# define the data generator\n",
    "shift = 0.06\n",
    "angle = 30 # 45\n",
    "\n",
    "# IMP: check the fill_mode that you set! \n",
    "image_data_gen_args = dict(featurewise_center=False, \n",
    "                             featurewise_std_normalization=False, \n",
    "                             # zca_whitening=True, \n",
    "                             rotation_range=angle,\n",
    "                             width_shift_range=shift, \n",
    "                             height_shift_range=shift,\n",
    "                             fill_mode = 'constant',\n",
    "                             cval = 0,\n",
    "                             horizontal_flip=False, \n",
    "                             vertical_flip=False,\n",
    "                             )\n",
    "\n",
    "datagen = ImageDataGenerator(**image_data_gen_args)\n",
    "# is not necessary for simple transformations\n",
    "# datagen.fit(x_train, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that we loaded the same model \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# performance on the modified data\n",
    "j_batch = 0 # counter to break an infinite loop\n",
    "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size):\n",
    "    # probabilities of being a specific digit\n",
    "    proba = model.predict(X_batch, verbose=0) \n",
    "    digits_predicted = np.argmax(proba, axis=1)\n",
    "    # show all images  \n",
    "    plot_digits(X_batch, digits_predicted) \n",
    "    \n",
    "    j_batch += 1\n",
    "    if (j_batch >= 3):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that we loaded the same model \n",
    "scores = model.evaluate_generator(datagen.flow(x_test, y_test, batch_size=batch_size), steps=len(x_test) / batch_size)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "# current_dir = os.getcwd()\n",
    "j_batch = 0 # counter to break an infinite loop\n",
    "# save_to_dir=(current_dir + '/data/images'), save_prefix='aug', save_format='png'): # if you want to save the images\n",
    "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size):\n",
    "    print(j_batch, \"th batch with the shapes:\", X_batch.shape, y_batch.shape)   \n",
    "    y_digits = np.nonzero(y_batch)[1]\n",
    "    # show all images\n",
    "    plot_digits(X_batch, y_digits) \n",
    "    \n",
    "    j_batch += 1\n",
    "    if (j_batch >= 3):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fits the model on batches with real-time data augmentation\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train) / batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# verify model on the initial data \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# verify model on the augmented data\n",
    "scores = model.evaluate_generator(datagen.flow(x_test, y_test, batch_size=batch_size), steps=len(x_test) / batch_size)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
